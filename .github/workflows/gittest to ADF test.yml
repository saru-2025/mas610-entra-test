name: üöÄ Deploy to Test ADF & Databricks

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy-test:
    runs-on: ubuntu-latest
    environment: test

    steps:
      # 1Ô∏è‚É£ Checkout Test repo
      - name: üß© Checkout Test repo
        uses: actions/checkout@v4

      # 2Ô∏è‚É£ Azure Login
      - name: üîê Azure Login
        uses: azure/login@v1
        with:
          creds: >
            {
              "clientId": "${{ secrets.SPCLIENTID }}",
              "clientSecret": "${{ secrets.SPSECRET }}",
              "tenantId": "${{ secrets.TENANTID }}",
              "subscriptionId": "${{ secrets.SUBSCRPTION }}"
            }

      # 3Ô∏è‚É£ Deploy Azure Data Factory template (ARM)
      - name: üöÄ Deploy Azure Data Factory ARM Template
        uses: Azure/arm-deploy@v1
        with:
          scope: resourcegroup
          resourceGroupName: rg_data_platform
          template: factory/adf-data-platform-test.json
          parameters: factory/arm-template-parameters.json
          deploymentName: adf-test-deployment
          failOnStdErr: false

      # 4Ô∏è‚É£ Install Databricks CLI
      - name: ‚öôÔ∏è Install Databricks CLI
        run: pip install databricks-cli

      # 5Ô∏è‚É£ Configure Databricks CLI
      - name: üîë Configure Databricks
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKSHOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKSTOKEN }}
        run: |
          echo "Setting up Databricks CLI..."
          databricks configure --token <<EOF
          $DATABRICKS_HOST
          $DATABRICKS_TOKEN
          EOF

      # 6Ô∏è‚É£ Upload notebooks to Test workspace
      - name: üì¶ Upload Notebooks to Test Workspace
        run: |
          echo "Uploading notebooks to Test workspace..."
          databricks workspace import_dir notebooks /Shared/Test_Notebooks --overwrite
