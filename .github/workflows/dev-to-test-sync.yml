name: ğŸš€ Deploy to Test ADF & Databricks

on:
  push:
    branches: [ main ]        # or use 'workflow_dispatch:' for manual
  workflow_dispatch:

jobs:
  deploy-test:
    runs-on: ubuntu-latest
    environment: test

    steps:
      # 1ï¸âƒ£ Checkout Test repo
      - name: ğŸ§© Checkout Test repo
        uses: actions/checkout@v4

      # 2ï¸âƒ£ Login to Azure
      - name: ğŸ” Azure Login
        uses: azure/login@v1
        with:
          creds: |
            {
              "clientId": "${{ secrets.AZURE_CLIENT_ID }}",
              "clientSecret": "${{ secrets.AZURE_CLIENT_SECRET }}",
              "tenantId": "${{ secrets.AZURE_TENANT_ID }}",
              "subscriptionId": "${{ secrets.AZURE_SUBSCRIPTION_ID }}"
            }

      # 3ï¸âƒ£ Deploy ADF artifacts (datasets, pipelines, triggers)
      - name: ğŸš€ Deploy Azure Data Factory JSONs
        uses: azure/data-factory-deploy-action@v1.3.3
        with:
          resourceGroupName: rg_data_platform_test
          dataFactoryName: adf-data-platform-test
          armTemplateFile: factory/adf-data-platform-test.json
          armTemplateParametersFile: factory/arm-template-parameters.json
          overwrite: true

      # 4ï¸âƒ£ Install Databricks CLI
      - name: âš™ï¸ Install Databricks CLI
        run: |
          pip install databricks-cli

      # 5ï¸âƒ£ Configure Databricks CLI for Test
      - name: ğŸ”‘ Configure Databricks
        run: |
          databricks configure --token <<EOF
          ${{ secrets.DATABRICKS_HOST }}
          ${{ secrets.DATABRICKS_TOKEN }}
          EOF

      # 6ï¸âƒ£ Deploy notebooks to Test workspace
      - name: ğŸ“¦ Deploy Databricks Notebooks
        run: |
          echo "Uploading notebooks to Test workspace..."
          databricks workspace import_dir \
            notebooks /Shared/Test_Notebooks --overwrite

